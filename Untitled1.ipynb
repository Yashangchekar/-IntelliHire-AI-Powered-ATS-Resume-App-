{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb3a7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " HarshavardhanRaoAriga\n",
      "CareerObjective:MygoalistocontinuallyrefinemyskillsinDataanalysis,visualization,and\n",
      "communication,whilestayingup-to-datewiththelatestindustrytrendsandbestpractices.Ultimately,I\n",
      "seektobecomeavaluableassettoanyorganizationbydeliveringhigh-quality,data-drivensolutionsthat\n",
      "positivelyimpactthebottomline.\n",
      "PersonalDetails\n",
      "D.O.B:-24June2001\n",
      "Languages:-English,Hindi,Marathi,Telugu\n",
      "Nationality:-Indian\n",
      "Ambernath,Maharashtra\n",
      "+919850572168\n",
      "harsh.glory129@gmail.com\n",
      "harshavardhan-rao-ariga-96381a193\n",
      "github.com/harshglory129\n",
      "TechnicalSkills\n",
      "Programming:Python,Java\n",
      "RDBMS:MySQL\n",
      "Visualization:Matplotlib,Seaborn,Plotly\n",
      "Mathematics:Statistics,LinearAlgebra\n",
      "Models:Classification&RegressionModels\n",
      "VersionControl:Github\n",
      "BITools:PowerBI,MSExcel\n",
      "SoftSkills\n",
      "Communication\n",
      "ProblemSolving\n",
      "DecisionMaking\n",
      "Teamwork&Collaboration\n",
      "CriticalThinking\n",
      "Courses&Certifications\n",
      "DataAnalysisUsingPython,IBM\n",
      "AWSCloudPractitioner:Technical\n",
      "EssentialsPart1and2,Skillsoft\n",
      "ProgrammingWithPython,Upgrad\n",
      "PythonLibraries,Upgrad\n",
      "Achievements&Activities\n",
      "2ndRankBSc-ITinCollege(2022)Education\n",
      "MastersinBusinessDataAnalytics-(2022-2023)\n",
      "ItvedantEducationPvt.Ltd,Andheri,Maharashtra\n",
      "CurrentlyPursuing\n",
      "B.Sc.InformationTechnology-(2019-2022)\n",
      "ModelCollegeofScienceandCommerce,Kalyan,Maharashtra\n",
      "Marks:-9.35CGPA\n",
      "Experience\n",
      "DataScienceandBusinessAnalyticIntern-(June2021–Aug2021)2mos\n",
      "TheSparksFoundation·Internship\n",
      "DataAnalystIntern-(June2022–Jul2022)1mos\n",
      "GlobalShala·Internship\n",
      "LeadGenAssociate(Operations)-(Jul2022–Feb2023)8mos\n",
      "DatamaticsBusinessSolutionsLtd.·Full-time\n",
      "Projects\n",
      "☑YoutubeEDAthroughAPI\n",
      "IusedGoogleDeveloperaccounttogetAPIKeyforYoutubetoaccessLivedataofTop\n",
      "10ChannelsofMusicArtists.UsingthestatisticaldataderivedfromJSONdataset\n",
      "extractedSubscribers,Title,Likes,Description,Duration,Comments,Views,etcto\n",
      "provideinsightsbyEDA.IusedPandas,Numpy,Plotly,Googleapiclient,NLTK,\n",
      "Wordcloudandotherpythonlibraries.\n",
      "☑ZomatoDatasetExploratoryDataAnalysis\n",
      "InthisProjectIhaveanalyzedmorethan50,000+OrderdatafromBangalorethrough\n",
      "ZomatobasedonName,Votes,Ratings,Cuisines,Price,Locationtoprovideinsightson\n",
      "Restaurants.IusedPandas,Numpy,re,Plotly,Seaborn,Matplotlib.\n",
      "☑WebScrapping(thmoviedb.org)\n",
      "IscrapedMovieswithName,Rating,Genre,ReleaseDate,RuntimeandDirectorsof\n",
      "1000MovieswithURLsobtainedthroughidsbypagination.IusedPandas,re,Requests\n",
      "&BeautifulSouplibraries.\n",
      "☑RetailStoreExploratoryDataAnalysis\n",
      "InthisprojectIhaveanalyzedSuperstorebasedonSales,Quantity,DiscountandProfit\n",
      "andcreatedaCorrelationHeat-map.DerivinginsightstomakeTechnologyhasthe\n",
      "highestsalesincategory,FurnituremadelessProfitevenwithmaximumdiscount.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def read_resume_text(uploaded_file):\n",
    "    if uploaded_file.name.endswith('.pdf'):\n",
    "        pdf_reader = PyPDF2.PdfReader(uploaded_file)\n",
    "        text = ' '\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    else:\n",
    "        resume_bytes = uploaded_file.read()\n",
    "        text = resume_bytes.decode('utf-8', errors='ignore')\n",
    "\n",
    "    return text\n",
    "\n",
    "with open('resume101.pdf', 'rb') as uploaded_file:\n",
    "    result_text = read_resume_text(uploaded_file)\n",
    "\n",
    "print(result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f23b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HarshavardhanRaoAriga CareerObjective MygoalistocontinuallyrefinemyskillsinDataanalysis visualization and communication whilestayingup to datewiththelatestindustrytrendsandbestpractices Ultimately I seektobecomeavaluableassettoanyorganizationbydeliveringhigh quality data drivensolutionsthat positivelyimpactthebottomline PersonalDetails D O B 24June2001 Languages English Hindi Marathi Telugu Nationality Indian Ambernath Maharashtra 919850572168 harsh glory129 gmail com harshavardhan rao ariga 96381a193 github com harshglory129 TechnicalSkills Programming Python Java RDBMS MySQL Visualization Matplotlib Seaborn Plotly Mathematics Statistics LinearAlgebra Models Classification RegressionModels VersionControl Github BITools PowerBI MSExcel SoftSkills Communication ProblemSolving DecisionMaking Teamwork Collaboration CriticalThinking Courses Certifications DataAnalysisUsingPython IBM AWSCloudPractitioner Technical EssentialsPart1and2 Skillsoft ProgrammingWithPython Upgrad PythonLibraries Upgrad Achievements Activities 2ndRankBSc ITinCollege 2022 Education MastersinBusinessDataAnalytics 2022 2023 ItvedantEducationPvt Ltd Andheri Maharashtra CurrentlyPursuing B Sc InformationTechnology 2019 2022 ModelCollegeofScienceandCommerce Kalyan Maharashtra Marks 9 35CGPA Experience DataScienceandBusinessAnalyticIntern June2021 Aug2021 2mos TheSparksFoundation Internship DataAnalystIntern June2022 Jul2022 1mos GlobalShala Internship LeadGenAssociate Operations Jul2022 Feb2023 8mos DatamaticsBusinessSolutionsLtd Full time Projects YoutubeEDAthroughAPI IusedGoogleDeveloperaccounttogetAPIKeyforYoutubetoaccessLivedataofTop 10ChannelsofMusicArtists UsingthestatisticaldataderivedfromJSONdataset extractedSubscribers Title Likes Description Duration Comments Views etcto provideinsightsbyEDA IusedPandas Numpy Plotly Googleapiclient NLTK Wordcloudandotherpythonlibraries ZomatoDatasetExploratoryDataAnalysis InthisProjectIhaveanalyzedmorethan50 000 OrderdatafromBangalorethrough ZomatobasedonName Votes Ratings Cuisines Price Locationtoprovideinsightson Restaurants IusedPandas Numpy re Plotly Seaborn Matplotlib WebScrapping thmoviedb org IscrapedMovieswithName Rating Genre ReleaseDate RuntimeandDirectorsof 1000MovieswithURLsobtainedthroughidsbypagination IusedPandas re Requests BeautifulSouplibraries RetailStoreExploratoryDataAnalysis InthisprojectIhaveanalyzedSuperstorebasedonSales Quantity DiscountandProfit andcreatedaCorrelationHeat map DerivinginsightstomakeTechnologyhasthe highestsalesincategory FurnituremadelessProfitevenwithmaximumdiscount\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "def read_resume_text(uploaded_file):\n",
    "    if uploaded_file.name.endswith('.pdf'):\n",
    "        pdf_reader = PyPDF2.PdfReader(uploaded_file)\n",
    "        text = ' '\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    else:\n",
    "        resume_bytes = uploaded_file.read()\n",
    "        text = resume_bytes.decode('utf-8', errors='ignore')\n",
    "\n",
    "    return text\n",
    "\n",
    "def separate_words(text):\n",
    "    # Using regular expression to find word boundaries\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return ' '.join(words)\n",
    "\n",
    "with open('resume101.pdf', 'rb') as uploaded_file:\n",
    "    result_text = read_resume_text(uploaded_file)\n",
    "\n",
    "separated_words = separate_words(result_text)\n",
    "print(separated_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7fc83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_words(text):\n",
    "    # Using regular expression to find word boundaries\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4129f298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yash Angchekar living inmumb\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6a1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
